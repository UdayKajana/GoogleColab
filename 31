import argparse
import json
import logging
import time
from io import BytesIO

import apache_beam as beam
import apache_beam.pvalue as pvl
import avro
import avro.io as avro_io
import avro.schema
from apache_beam.io import WriteToText
from apache_beam.io.gcp.pubsub import ReadFromPubSub
from apache_beam.options.pipeline_options import PipelineOptions
from apache_beam.transforms import window

# Rest of the imports and argument parsing remain the same...

class DecodeAvroRecords(beam.DoFn):
    def process(self, element):
        # Your existing decode logic remains the same...
        # At the end, yield the reformatted message
        try:
            # Existing decoding logic...
            reformatted = reformat_input_msg_schema(message)
            logging.info(f"TEMP_LOG: reformatted={reformatted}")
            yield pvl.TaggedOutput("valid_recs", reformatted)
        except Exception as e:
            logging.error(f"Error in Decoding::{element}")
            logging.error(e)
            yield pvl.TaggedOutput("invalid_recs", element)

def dict_to_str(row):
    try:
        raw_data = json.loads(row['rawdata'])
        lst = list(raw_data.values())
        row_str = ",".join([str(i) for i in lst])
        return row_str
    except Exception as e:
        logging.error(f"Error in dict_to_str: {e}")
        return None

def format_window_fn(window_info):
    return f"{window_info.start.strftime('%Y%m%d-%H%M')}"

# Pipeline definition
pipeline_options = PipelineOptions.from_dictionary(options)
p = beam.Pipeline(options=pipeline_options)

# Read from PubSub
pubsub_data = (p 
    | f'ReadFromPubsub {known_args.input_sub}' 
    >> ReadFromPubSub(subscription=f"projects/{known_args.project}/subscriptions/{known_args.input_sub}"))

# Decode messages
decoded_result = pubsub_data | 'Decode Msg' >> beam.ParDo(DecodeAvroRecords())

# Access the valid records
valid_records = decoded_result[DecodeAvroRecords.valid_recs]

# Debug prints for valid records
valid_records | 'Print Valid Data' >> beam.Map(
    lambda element: logging.info(f"Valid Data: {element}")
)

# Window the data into 1-minute fixed windows
windowed_data = (valid_records 
    | "Window" >> beam.WindowInto(
        window.FixedWindows(60),  # 60 seconds
        trigger=trigger.AfterWatermark(),
        accumulation_mode=trigger.AccumulationMode.DISCARDING
    )
)

# Convert to CSV string format
str_rows = windowed_data | "DictToStr" >> beam.Map(dict_to_str)

# Write to GCS with windowed file names
_ = (str_rows 
    | "Write-To-File" >> WriteToText(
        known_args.gcs_folder_path,
        file_name_suffix=".csv",
        header=headers.get("vrepair_ticket_opened_norm_v0"),
        window_fn=format_window_fn
    )
)

# Print invalid records for debugging
invalid_records = decoded_result[DecodeAvroRecords.invalid_recs]
invalid_records | "Print Invalid Records" >> beam.Map(
    lambda element: logging.error(f"Invalid record: {element}")
)

result = p.run()
print(f'Created template at {known_args.template_location}.')
