import io
from google.cloud import pubsub_v1
import pandas as pd
import avro.schema
from avro.io import DatumReader, BinaryDecoder
from io import BytesIO

# Define the Avro schema
schema_definition = {
    "type": "record",
    "name": "ChurnData",
    "fields": [
        {"name": "ont_activation_date", "type": ["null", "string"]},
        {"name": "data_circuit_id", "type": ["null", "string"]},
        {"name": "circuit_id", "type": ["null", "string"]},
        {"name": "video_circuit_id", "type": ["null", "string"]},
        {"name": "service_type", "type": ["null", "string"]},
        {"name": "address_id", "type": ["null", "string"]},
        {"name": "vision_account_id", "type": ["null", "string"]},
        {"name": "vision_customer_id", "type": ["null", "string"]},
        {"name": "address_type", "type": ["null", "string"]},
        {"name": "line_of_business", "type": ["null", "string"]}
    ]
}

def process_avro_message(message):
    try:
        # Parse the Avro schema
        avro_schema = avro.schema.parse(schema_definition)
        
        # Create a DatumReader with the schema
        reader = DatumReader(avro_schema)
        
        # Get the message data
        avro_data = message.data
        bytes_reader = BytesIO(avro_data)
        decoder = BinaryDecoder(bytes_reader)
        
        rows = []
        try:
            # Read records from the Avro message
            while True:
                try:
                    record = reader.read(decoder)
                    processed_record = {}
                    
                    # Process each field in the record
                    for key in schema_definition['fields']:
                        field_name = key['name']
                        value = record.get(field_name)
                        
                        # Handle None values and convert complex types to strings if needed
                        if value is None:
                            processed_record[field_name] = None
                        elif isinstance(value, (dict, list)):
                            processed_record[field_name] = str(value)
                        else:
                            processed_record[field_name] = value
                    
                    rows.append(processed_record)
                
                except EOFError:
                    break
            
            # Convert to DataFrame and save to CSV
            df = pd.DataFrame(rows)
            csv_filename = f'pubsub_data_{pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")}.csv'
            df.to_csv(csv_filename, index=False)
            
            print(f"Saved {len(df)} records to {csv_filename}")
            message.ack()
            return df
        
        except Exception as decode_error:
            print(f"Error decoding Avro message: {decode_error}")
            message.nack()
            return None
    
    except Exception as e:
        print(f"Error processing message: {e}")
        message.nack()
        return None

# Pub/Sub configuration
project_id = "vz-it-np-gudv-dev-vzntdo-0"
subscription_id = "wireline_churn_test_topic-sub"

# Create Pub/Sub subscriber
subscriber = pubsub_v1.SubscriberClient()
subscription_path = f"projects/{project_id}/subscriptions/{subscription_id}"

# Subscribe and process messages
streaming_pull_future = subscriber.subscribe(subscription_path, callback=process_avro_message)

with subscriber:
    try:
        streaming_pull_future.result()
    except TimeoutError:
        streaming_pull_future.cancel()
        streaming_pull_future.result()
