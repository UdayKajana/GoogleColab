import apache_beam as beam
from apache_beam.options.pipeline_options import PipelineOptions
from google.cloud import pubsub_v1
from apache_beam.transforms.window import FixedWindows
from fastavro import reader
import io
import csv

# Define your Pub/Sub topic and subscription
project_id = "vz-it-np-gudv-dev-vzntdo-0"
subscription_id = "wireline_churn_test_topic-sub"
subscription_path = f"projects/{project_id}/subscriptions/{subscription_id}"

# Define your GCS bucket and file path
gcs_bucket = "vznet-test"
gcs_file_path = "wireline_churn_test/tgt/customer_profile.csv"

# Avro schema
schema = {
    "namespace": "example.avro",
    "type": "record",
    "name": "customerprofile",
    "fields": [
        {"name": "ont_activation_date", "type": ["string", "null"]},
        {"name": "data_circuit_id", "type": ["string", "null"]},
        {"name": "circuit_id", "type": ["string", "null"]},
        {"name": "video_circuit_id", "type": ["string", "null"]},
        {"name": "service_type", "type": ["string", "null"]},
        {"name": "address_id", "type": "long"},
        {"name": "vision_account_id", "type": ["string", "null"]},
        {"name": "vision_customer_id", "type": ["string", "null"]},
        {"name": "address_type", "type": ["string", "null"]},
        {"name": "line_of_business", "type": ["string", "null"]}
    ]
}

def parse_avro_message(message):
    avro_bytes = message.data
    avro_file = io.BytesIO(avro_bytes)
    avro_reader = reader(avro_file)
    for record in avro_reader:
        yield record.values()

def format_csv_line(record):
    """Formats a record as a CSV line."""
    return ','.join(str(field) for field in record)

# Create a Beam pipeline
with beam.Pipeline(options=PipelineOptions()) as pipeline:
    # Read messages from Pub/Sub
    messages = (
        pipeline
        | "ReadFromPubSub" >> beam.io.ReadFromPubSub(subscription=subscription_path)
    )
    windowed_data = (
        messages
        | "windowing" >> beam.WindowInto(FixedWindows(60)) # Window into 1-minute intervals
    )
    # Parse Avro messages
    parsed_data = (
        windowed_data
        | "ParseAvroMessages" >> beam.FlatMap(parse_avro_message)
    )

    gbk = (
        parsed_data | "GroupByKey" >> beam.GroupByKey()
    )

    # Format as CSV
    csv_lines = (
        gbk
        | "FormatCSVLines" >> beam.Map(format_csv_line)
    )

    # Write to GCS
    (
        csv_lines
        | "WriteToGCS" >> beam.io.WriteToText(
            f"gs://{gcs_bucket}/{gcs_file_path}",
            header=','.join(field['name'] for field in schema['fields']),
            file_name_suffix=".csv",
        )
    )
