import apache_beam as beam
from apache_beam.options.pipeline_options import PipelineOptions
from fastavro import reader
import io
import csv
import logging
from io import BytesIO
import fastavro

logging.getLogger().setLevel(logging.INFO)

# Define project and subscription details
project_id = "vz-it-np-gudv-dev-vzntdo-0"
subscription_id = "wireline_churn_test_topic-sub"
subscription_path = f"projects/{project_id}/subscriptions/{subscription_id}"
gcs_bucket = "vznet-test"
gcs_output_path = "wireline_churn_test/tgt/customer_profile"

def extract_avro_schema_from_message(message_data):
    try:
        # Use fastavro to read the schema
        bytes_reader = BytesIO(message_data)
        avro_reader = fastavro.reader(bytes_reader)
        
        # Extract the writer's schema
        return avro_reader.writer_schema
    except Exception as e:
        logging.error(f"Error extracting schema: {e}")
        return None

def process_avro_message(avro_data):
    """
    Convert Avro data to a CSV string.
    """
    try:
        # Extract the writer's schema
        writer_schema = extract_avro_schema_from_message(avro_data)
        if not writer_schema:
            raise ValueError("Failed to extract schema from Avro message")
        
        # Reset the bytes reader
        bytes_reader = BytesIO(avro_data)
        
        # Process records
        rows = []
        for record in fastavro.reader(bytes_reader, writer_schema):
            processed_record = {key: str(value) if value is not None else "" for key, value in record.items()}
            rows.append(processed_record)
        
        # Convert to CSV
        if rows:
            fieldnames = list(rows[0].keys())
            csv_buffer = io.StringIO()
            writer = csv.DictWriter(csv_buffer, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(rows)
            return csv_buffer.getvalue()
        else:
            logging.warning("No records could be processed from the Avro data")
            return None
    
    except Exception as e:
        logging.error(f"Error processing Avro message: {e}")
        return None

def run_pipeline():
    pipeline_options = PipelineOptions(
        streaming=True,
        project=project_id,
        temp_location=f"gs://{gcs_bucket}/wireline_churn_test/tmp",
        region="us-central1"
    )

    with beam.Pipeline(options=pipeline_options) as pipeline:
        # Read messages from Pub/Sub
        messages = (pipeline 
                    | "ReadFromPubSub" >> beam.io.ReadFromPubSub(subscription=subscription_path)
                    | "DecodeMessages" >> beam.Map(lambda x: x.decode('utf-8'))  # Decode byte strings to UTF-8
                   )

        # Process Avro messages and convert to CSV
        csv_data = (messages
                    | "ProcessAvroToCSV" >> beam.Map(lambda msg: process_avro_message(BytesIO(msg).getvalue()))
                    )

        # Write CSV data to GCS
        _ = (csv_data 
             | "WriteToGCS" >> beam.io.WriteToText(
                 file_path_prefix=f"gs://{gcs_bucket}/{gcs_output_path}",
                 file_name_suffix=".csv",
                 shard_name_template="-SSSSS-of-NNNNN"
             ))

if __name__ == '__main__':
    run_pipeline()
