import argparse
import logging
import apache_beam as beam
from apache_beam.options.pipeline_options import PipelineOptions
from apache_beam.options.value_provider import ValueProvider
import datetime

class LogMessageWithDate(beam.DoFn):
    """Logs the message with a timestamp."""
    def process(self, message):
        current_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_message = f"Message received at {current_time}: {message}"
        logging.info(log_message)  # Use logging.info for Dataflow logs
        yield message  # Important to yield the element for downstream processing

def run(argv=None):
    """Main entry point; defines and runs the pipeline."""
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--subscription",
        dest="subscription",
        required=True,
        help="Pub/Sub subscription to read from (e.g., projects/your-project/subscriptions/your-subscription).",
    )
    parser.add_argument(
        "--output",
        dest="output",
        required=True,
        help="Output file to write results to.",
    )

    known_args, pipeline_args = parser.parse_known_args(argv)

    # Use ValueProvider to defer subscription retrieval
    subscription_provider = ValueProvider(
        lambda: known_args.subscription,  # Lambda to defer evaluation
        str,
    )

    pipeline_options = PipelineOptions(pipeline_args)
    pipeline_options.view_as(beam.options.pipeline_options.StandardOptions).streaming = True

    with beam.Pipeline(options=pipeline_options) as pipeline:
        messages = (
            pipeline
            | "ReadFromPubSub" >> beam.io.ReadFromPubSub(subscription=subscription_provider)
            | "Decode" >> beam.Map(lambda x: x.decode())
            | "LogMessageWithDate" >> beam.ParDo(LogMessageWithDate())
            | "WriteToText" >> beam.io.WriteToText(known_args.output)
        )

if __name__ == "__main__":
    logging.getLogger().setLevel(logging.INFO)  # Set logging level
    run()
